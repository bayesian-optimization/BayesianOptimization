{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for mypackage",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:563\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayes_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianOptimization\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayes_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UtilityFunction\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\python\\BayesianOptimization\\bayes_opt\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstraint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstraintModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmypackage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesianOptimization\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraintModel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequentialDomainReductionTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:1008\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:981\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    976\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\metadata\\__init__.py:565\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscover(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: No package metadata was found for mypackage"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "Lets create a target 1-D function with multiple local maxima to test and visualize how the [BayesianOptimization](https://github.com/fmfn/BayesianOptimization) package works. The target function we will try to maximize is the following:\n",
    "\n",
    "$$f(x) = e^{-(x - 2)^2} + e^{-\\frac{(x - 6)^2}{10}} + \\frac{1}{x^2 + 1}, $$ its maximum is at $x = 2$ and we will restrict the interval of interest to $x \\in (-2, 10)$.\n",
    "\n",
    "Notice that, in practice, this function is unknown, the only information we have is obtained by sequentially probing it at different points. Bayesian Optimization works by constructing a posterior distribution of functions that best fit the data observed and choosing the next probing point by balancing exploration and exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(x):\n",
    "    return np.exp(-(x - 2)**2) + np.exp(-(x - 6)**2/10) + 1/ (x**2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 10, 10000).reshape(-1, 1)\n",
    "y = target(x)\n",
    "\n",
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BayesianOptimization Object\n",
    "\n",
    "Enter the target function to be maximized, its variable(s) and their corresponding ranges. A minimum number of 2 initial guesses is necessary to kick start the algorithms, these can either be random or user defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(target, {'x': (-2, 10)}, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the Upper Confidence Bound (UCB) as our utility function. It has the free parameter\n",
    "$\\kappa$ which control the balance between exploration and exploitation; we will set $\\kappa=5$ which, in this case, makes the algorithm quite bold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_function = UtilityFunction(kind=\"ucb\", kappa=5)\n",
    "optimizer.maximize(init_points=2, n_iter=0, acquisition_function = acq_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and visualizing the algorithm at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first define a couple functions to make plotting easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(optimizer, x_obs, y_obs, grid):\n",
    "    optimizer._gp.fit(x_obs, y_obs)\n",
    "\n",
    "    mu, sigma = optimizer._gp.predict(grid, return_std=True)\n",
    "    return mu, sigma\n",
    "\n",
    "def plot_gp(optimizer, x, y):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    steps = len(optimizer.space)\n",
    "    fig.suptitle(\n",
    "        'Gaussian Process and Utility Function After {} Steps'.format(steps),\n",
    "        fontdict={'size':30}\n",
    "    )\n",
    "    \n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
    "    axis = plt.subplot(gs[0])\n",
    "    acq = plt.subplot(gs[1])\n",
    "    \n",
    "    x_obs = np.array([[res[\"params\"][\"x\"]] for res in optimizer.res])\n",
    "    y_obs = np.array([res[\"target\"] for res in optimizer.res])\n",
    "    \n",
    "    mu, sigma = posterior(optimizer, x_obs, y_obs, x)\n",
    "    axis.plot(x, y, linewidth=3, label='Target')\n",
    "    axis.plot(x_obs.flatten(), y_obs, 'D', markersize=8, label=u'Observations', color='r')\n",
    "    axis.plot(x, mu, '--', color='k', label='Prediction')\n",
    "\n",
    "    axis.fill(np.concatenate([x, x[::-1]]), \n",
    "              np.concatenate([mu - 1.9600 * sigma, (mu + 1.9600 * sigma)[::-1]]),\n",
    "        alpha=.6, fc='c', ec='None', label='95% confidence interval')\n",
    "    \n",
    "    axis.set_xlim((-2, 10))\n",
    "    axis.set_ylim((None, None))\n",
    "    axis.set_ylabel('f(x)', fontdict={'size':20})\n",
    "    axis.set_xlabel('x', fontdict={'size':20})\n",
    "    \n",
    "    utility_function = UtilityFunction(kind=\"ucb\", kappa=5, xi=0)\n",
    "    utility = utility_function.utility(x, optimizer._gp, 0)\n",
    "    acq.plot(x, utility, label='Utility Function', color='purple')\n",
    "    acq.plot(x[np.argmax(utility)], np.max(utility), '*', markersize=15, \n",
    "             label=u'Next Best Guess', markerfacecolor='gold', markeredgecolor='k', markeredgewidth=1)\n",
    "    acq.set_xlim((-2, 10))\n",
    "    acq.set_ylim((0, np.max(utility) + 0.5))\n",
    "    acq.set_ylabel('Utility', fontdict={'size':20})\n",
    "    acq.set_xlabel('x', fontdict={'size':20})\n",
    "    \n",
    "    axis.legend(loc=2, bbox_to_anchor=(1.01, 1), borderaxespad=0.)\n",
    "    acq.legend(loc=2, bbox_to_anchor=(1.01, 1), borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two random points\n",
    "\n",
    "After we probe two points at random, we can fit a Gaussian Process and start the bayesian optimization procedure. Two points should give us a uneventful posterior with the uncertainty growing as we go further from the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After one step of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After two steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After three steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After four steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After five steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After six steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After seven steps of GP (and two random points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=0, n_iter=1, acquisition_function=acq_function)\n",
    "plot_gp(optimizer, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping\n",
    "\n",
    "After just a few points the algorithm was able to get pretty close to the true maximum. It is important to notice that the trade off between exploration (exploring the parameter space) and exploitation (probing points near the current known maximum) is fundamental to a succesful bayesian optimization procedure. The utility function being used here (Upper Confidence Bound - UCB) has a free parameter $\\kappa$ that allows the user to make the algorithm more or less conservative. Additionally, the larger the initial set of random points explored, the less likely the algorithm is to get stuck in local minima due to being too conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
